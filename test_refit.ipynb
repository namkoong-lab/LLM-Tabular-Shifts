{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle \n",
    "from tqdm import tqdm\n",
    "\n",
    "import sys\n",
    "sys.path.append('/user/yz3587/llm-dro/code/embedding/data_processing/')\n",
    "from embed import *\n",
    "from train import *\n",
    "\n",
    "from src.mlp_concat import *\n",
    "from src.mlp_e5 import *\n",
    "from src.mlp import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 'AL,AK,AZ,AR,CA,CO,CT,DE,FL,GA,HI,ID,IL,IN,IA,KS,KY,LA,ME,MD,MA,MI,MN,MS,MO,MT,NE,NV,NH,NJ,NM,NY,NC,ND,OH,OK,OR,PA,RI,SC,SD,TN,TX,UT,VT,VA,WA,WV,WI,WY,PR'\n",
    "all_states = s.split(',')\n",
    "state_to_idx = {state: idx for idx, state in enumerate(all_states)}\n",
    "\n",
    "state_dict = {\n",
    "    'AL': 'Alabama','AK': 'Alaska','AZ': 'Arizona','AR': 'Arkansas','CA': 'California','CO': 'Colorado','CT': 'Connecticut',\n",
    "    'DE': 'Delaware','FL': 'Florida','GA': 'Georgia','HI': 'Hawaii','ID': 'Idaho','IL': 'Illinois','IN': 'Indiana','IA': 'Iowa',\n",
    "    'KS': 'Kansas','KY': 'Kentucky','LA': 'Louisiana','ME': 'Maine','MD': 'Maryland','MA': 'Massachusetts','MI': 'Michigan',\n",
    "    'MN': 'Minnesota','MS': 'Mississippi','MO': 'Missouri','MT': 'Montana','NE': 'Nebraska','NV': 'Nevada','NH': 'New Hampshire',\n",
    "    'NJ': 'New Jersey','NM': 'New Mexico','NY': 'New York','NC': 'North Carolina','ND': 'North Dakota','OH': 'Ohio','OK': 'Oklahoma',\n",
    "    'OR': 'Oregon','PA': 'Pennsylvania','RI': 'Rhode Island','SC': 'South Carolina','SD': 'South Dakota','TN': 'Tennessee','TX': 'Texas',\n",
    "    'UT': 'Utah','VT': 'Vermont','VA': 'Virginia','WA': 'Washington','WV': 'West Virginia','WI': 'Wisconsin','WY': 'Wyoming',\n",
    "    'PR': 'Puerto Rico'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example\n",
    "source_state = 'HI'\n",
    "source_state_list = source_state.split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(method, state, root_dir, num_train=20000, num_val=500, num_test=5000):\n",
    "    if method == 'concat':\n",
    "        X, y = get_concat_data('income', state, root_dir)\n",
    "    elif method == 'e5':\n",
    "        X, y = get_e5_data('income', 'domainlabel', state, root_dir)\n",
    "    elif method == 'one_hot':\n",
    "        X, y = get_onehot_data('income', state, False, root_dir, year=2018)\n",
    "\n",
    "    n = X.shape[0]\n",
    "    if n < num_train + num_val + num_test:\n",
    "        num_train = int(num_train * n / (num_train + num_val + num_test))\n",
    "        num_val = int(num_val * n / (num_train + num_val + num_test))\n",
    "        num_test = n - num_train - num_val\n",
    "\n",
    "    # Setting the random seed to ensure reproducibility\n",
    "    np.random.seed(42)  # You can use any number here as your seed\n",
    "    # Combining the data into a single array for shuffling\n",
    "    data = np.column_stack((X, y))\n",
    "    np.random.shuffle(data)\n",
    "    # Splitting the data back into features and labels\n",
    "    X, y = data[:, :-1], data[:, -1]\n",
    "    # Splitting the data into train, validation, and test sets\n",
    "    trainx, trainy = X[:num_train], y[:num_train]\n",
    "    valx, valy = X[num_train:num_train+num_val], y[num_train:num_train+num_val]\n",
    "    testx, testy = X[-num_test:], y[-num_test:]\n",
    "    return trainx, trainy, valx, valy, testx, testy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One hot baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for state in source_state_list:\n",
    "    root_dir = '/shared/share_mala/llm-dro/income/'\n",
    "    trainx, trainy, valx, valy, testx, testy = load_data('e5', state, root_dir)\n",
    "    # concat all train data into one\n",
    "    if state == source_state_list[0]:\n",
    "        X_train = trainx\n",
    "        y_train = trainy\n",
    "    else:\n",
    "        X_train = np.concatenate((X_train, trainx), axis=0)\n",
    "        y_train = np.concatenate((y_train, trainy), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6063, 4096)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = '/shared/share_mala/llm-dro/'\n",
    "task_name = 'income'\n",
    "source_state_str = 'CA'\n",
    "embedding_method = 'e5'\n",
    "prompt_method = 'domainlabel'\n",
    "model_dir = f'{save_dir}/save_models/{task_name}/{source_state_str}/{embedding_method}/{prompt_method}/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_116187/3109507003.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_train = torch.tensor(y_train).long()\n"
     ]
    }
   ],
   "source": [
    "## train model\n",
    "domainlabel_model = MLPe5Classifier(input_dim=X_train.shape[1], num_classes = 2, hidden_dim=64)\n",
    "y_train = torch.tensor(y_train).long()\n",
    "domainlabel_model.load(5, model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source State: \n",
      "average train acc: 0.743, average train f1: 0.739\n",
      "average val acc: 0.781, average val f1: 0.780\n",
      "average test acc: 0.740, average test f1: 0.739\n"
     ]
    }
   ],
   "source": [
    "domainlabel_source_train_acc_dict, domainlabel_source_val_acc_dict, domainlabel_source_test_acc_dict = dict(), dict(), dict()\n",
    "domainlabel_source_train_f1_dict, domainlabel_source_val_f1_dict, domainlabel_source_test_f1_dict = dict(), dict(), dict()\n",
    "\n",
    "## report training, val, testing performance for each state\n",
    "for state in source_state_list:\n",
    "    root_dir = '/shared/share_mala/llm-dro/income/'\n",
    "    trainx, trainy, valx, valy, testx, testy = load_data('e5', state, root_dir)\n",
    "    train_acc, train_f1 = domainlabel_model.score(trainx, trainy)\n",
    "    val_acc, val_f1 = domainlabel_model.score(valx, valy)\n",
    "    test_acc, test_f1 = domainlabel_model.score(testx, testy)\n",
    "    \n",
    "    domainlabel_source_train_acc_dict[state], domainlabel_source_val_acc_dict[state], domainlabel_source_test_acc_dict[state] = train_acc, val_acc, test_acc\n",
    "    domainlabel_source_train_f1_dict[state], domainlabel_source_val_f1_dict[state], domainlabel_source_test_f1_dict[state] = train_f1, val_f1, test_f1\n",
    "\n",
    "print(\"Source State: \")\n",
    "print(f\"average train acc: {np.mean(list(domainlabel_source_train_acc_dict.values())):.3f}, average train f1: {np.mean(list(domainlabel_source_train_f1_dict.values())):.3f}\")\n",
    "print(f\"average val acc: {np.mean(list(domainlabel_source_val_acc_dict.values())):.3f}, average val f1: {np.mean(list(domainlabel_source_val_f1_dict.values())):.3f}\")\n",
    "print(f\"average test acc: {np.mean(list(domainlabel_source_test_acc_dict.values())):.3f}, average test f1: {np.mean(list(domainlabel_source_test_f1_dict.values())):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target State: \n",
      "average val acc: 0.735, average val f1: 0.729\n",
      "average test acc: 0.694, average test f1: 0.687\n"
     ]
    }
   ],
   "source": [
    "domainlabel_target_val_acc_dict, domainlabel_target_test_acc_dict =  dict(), dict()\n",
    "domainlabel_target_val_f1_dict, domainlabel_target_test_f1_dict =  dict(), dict()\n",
    "for state in ['IA']:\n",
    "    if state not in source_state_list:\n",
    "        root_dir = '/shared/share_mala/llm-dro/income/'\n",
    "        trainx, trainy, valx, valy, testx, testy = load_data('e5', state, root_dir)\n",
    "        val_acc, val_f1 = domainlabel_model.score(valx, valy)\n",
    "        test_acc, test_f1 = domainlabel_model.score(testx, testy)\n",
    "        \n",
    "        domainlabel_target_val_acc_dict[state], domainlabel_target_test_acc_dict[state] = val_acc, test_acc\n",
    "        domainlabel_target_val_f1_dict[state], domainlabel_target_test_f1_dict[state] = val_f1, test_f1\n",
    "\n",
    "print(\"Target State: \")\n",
    "print(f\"average val acc: {np.mean(list(domainlabel_target_val_acc_dict.values())):.3f}, average val f1: {np.mean(list(domainlabel_target_val_f1_dict.values())):.3f}\")\n",
    "print(f\"average test acc: {np.mean(list(domainlabel_target_test_acc_dict.values())):.3f}, average test f1: {np.mean(list(domainlabel_target_test_f1_dict.values())):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "## refit one hot model on one target state\n",
    "\n",
    "target_state = 'IA'\n",
    "root_dir = '/shared/share_mala/llm-dro/income/'\n",
    "trainx, trainy, valx, valy, testx, testy = load_data('e5', target_state, root_dir, num_train=20000, num_val=32, num_test=5000)\n",
    "\n",
    "refitx = valx\n",
    "refity = valy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/user/yz3587/llm-dro/code/embedding/src/mlp_e5.py:151: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(y)\n",
      "100%|██████████| 51/51 [00:22<00:00,  2.31it/s]\n"
     ]
    }
   ],
   "source": [
    "## train model\n",
    "refity = torch.tensor(refity).long()\n",
    "\n",
    "domainlabel_model.refit_epochs = 50\n",
    "domainlabel_model.refit_lr = 0.001\n",
    "domainlabel_model.refit(refitx, refity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source State: \n",
      "average train acc: 0.715, average train f1: 0.653\n",
      "average val acc: 0.698, average val f1: 0.645\n",
      "average test acc: 0.692, average test f1: 0.640\n"
     ]
    }
   ],
   "source": [
    "domainlabel_source_train_acc_dict, domainlabel_source_val_acc_dict, domainlabel_source_test_acc_dict = dict(), dict(), dict()\n",
    "domainlabel_source_train_f1_dict, domainlabel_source_val_f1_dict, domainlabel_source_test_f1_dict = dict(), dict(), dict()\n",
    "\n",
    "## report training, val, testing performance for each state\n",
    "for state in source_state_list:\n",
    "    root_dir = '/shared/share_mala/llm-dro/income/'\n",
    "    trainx, trainy, valx, valy, testx, testy = load_data('e5', state, root_dir)\n",
    "    train_acc, train_f1 = domainlabel_model.score(trainx, trainy)\n",
    "    val_acc, val_f1 = domainlabel_model.score(valx, valy)\n",
    "    test_acc, test_f1 = domainlabel_model.score(testx, testy)\n",
    "    \n",
    "    domainlabel_source_train_acc_dict[state], domainlabel_source_val_acc_dict[state], domainlabel_source_test_acc_dict[state] = train_acc, val_acc, test_acc\n",
    "    domainlabel_source_train_f1_dict[state], domainlabel_source_val_f1_dict[state], domainlabel_source_test_f1_dict[state] = train_f1, val_f1, test_f1\n",
    "\n",
    "print(\"Source State: \")\n",
    "print(f\"average train acc: {np.mean(list(domainlabel_source_train_acc_dict.values())):.3f}, average train f1: {np.mean(list(domainlabel_source_train_f1_dict.values())):.3f}\")\n",
    "print(f\"average val acc: {np.mean(list(domainlabel_source_val_acc_dict.values())):.3f}, average val f1: {np.mean(list(domainlabel_source_val_f1_dict.values())):.3f}\")\n",
    "print(f\"average test acc: {np.mean(list(domainlabel_source_test_acc_dict.values())):.3f}, average test f1: {np.mean(list(domainlabel_source_test_f1_dict.values())):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target State: \n",
      "average val acc: 0.732, average val f1: 0.668\n",
      "average test acc: 0.713, average test f1: 0.622\n"
     ]
    }
   ],
   "source": [
    "domainlabel_target_val_acc_dict, domainlabel_target_test_acc_dict =  dict(), dict()\n",
    "domainlabel_target_val_f1_dict, domainlabel_target_test_f1_dict =  dict(), dict()\n",
    "for state in ['IA']:\n",
    "    if state not in source_state_list:\n",
    "        root_dir = '/shared/share_mala/llm-dro/income/'\n",
    "        trainx, trainy, valx, valy, testx, testy = load_data('e5', state, root_dir)\n",
    "        val_acc, val_f1 = domainlabel_model.score(valx, valy)\n",
    "        test_acc, test_f1 = domainlabel_model.score(testx, testy)\n",
    "        \n",
    "        domainlabel_target_val_acc_dict[state], domainlabel_target_test_acc_dict[state] = val_acc, test_acc\n",
    "        domainlabel_target_val_f1_dict[state], domainlabel_target_test_f1_dict[state] = val_f1, test_f1\n",
    "\n",
    "print(\"Target State: \")\n",
    "print(f\"average val acc: {np.mean(list(domainlabel_target_val_acc_dict.values())):.3f}, average val f1: {np.mean(list(domainlabel_target_val_f1_dict.values())):.3f}\")\n",
    "print(f\"average test acc: {np.mean(list(domainlabel_target_test_acc_dict.values())):.3f}, average test f1: {np.mean(list(domainlabel_target_test_f1_dict.values())):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## llm baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for state in source_state_list:\n",
    "    root_dir = '/shared/share_mala/llm-dro/income/'\n",
    "    trainx, trainy, valx, valy, testx, testy = load_data('e5', state, root_dir)\n",
    "    # concat all train data into one\n",
    "    if state == source_state_list[0]:\n",
    "        X_train = trainx\n",
    "        y_train = trainy\n",
    "    else:\n",
    "        X_train = np.concatenate((X_train, trainx), axis=0)\n",
    "        y_train = np.concatenate((y_train, trainy), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 201/201 [03:18<00:00,  1.01it/s]\n"
     ]
    }
   ],
   "source": [
    "## train model\n",
    "baseline_model = MLPe5Classifier(input_dim=4096, num_classes = 2, hidden_dim=64)\n",
    "baseline_model.train_epochs = 200\n",
    "baseline_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source State: \n",
      "average train acc: 0.843, average train f1: 0.830\n",
      "average val acc: 0.814, average val f1: 0.804\n",
      "average test acc: 0.820, average test f1: 0.803\n"
     ]
    }
   ],
   "source": [
    "baseline_source_train_acc_dict, baseline_source_val_acc_dict, baseline_source_test_acc_dict = dict(), dict(), dict()\n",
    "baseline_source_train_f1_dict, baseline_source_val_f1_dict, baseline_source_test_f1_dict = dict(), dict(), dict()\n",
    "\n",
    "## report training, val, testing performance for each state\n",
    "for state in source_state_list:\n",
    "    root_dir = '/shared/share_mala/llm-dro/income/'\n",
    "    trainx, trainy, valx, valy, testx, testy = load_data('e5', state, root_dir)\n",
    "    train_acc, train_f1 = baseline_model.score(trainx, trainy)\n",
    "    val_acc, val_f1 = baseline_model.score(valx, valy)\n",
    "    test_acc, test_f1 = baseline_model.score(testx, testy)\n",
    "    \n",
    "    baseline_source_train_acc_dict[state], baseline_source_val_acc_dict[state], baseline_source_test_acc_dict[state] = train_acc, val_acc, test_acc\n",
    "    baseline_source_train_f1_dict[state], baseline_source_val_f1_dict[state], baseline_source_test_f1_dict[state] = train_f1, val_f1, test_f1\n",
    "\n",
    "print(\"Source State: \")\n",
    "print(f\"average train acc: {np.mean(list(baseline_source_train_acc_dict.values())):.3f}, average train f1: {np.mean(list(baseline_source_train_f1_dict.values())):.3f}\")\n",
    "print(f\"average val acc: {np.mean(list(baseline_source_val_acc_dict.values())):.3f}, average val f1: {np.mean(list(baseline_source_val_f1_dict.values())):.3f}\")\n",
    "print(f\"average test acc: {np.mean(list(baseline_source_test_acc_dict.values())):.3f}, average test f1: {np.mean(list(baseline_source_test_f1_dict.values())):.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target State: \n",
      "average val acc: 0.738, average val f1: 0.729\n",
      "average test acc: 0.728, average test f1: 0.718\n"
     ]
    }
   ],
   "source": [
    "baseline_target_val_acc_dict, baseline_target_test_acc_dict =  dict(), dict()\n",
    "baseline_target_val_f1_dict, baseline_target_test_f1_dict =  dict(), dict()\n",
    "for state in all_states:\n",
    "    if state not in source_state_list:\n",
    "        root_dir = '/shared/share_mala/llm-dro/income/'\n",
    "        trainx, trainy, valx, valy, testx, testy = load_data('e5', state, root_dir)\n",
    "        val_acc, val_f1 = baseline_model.score(valx, valy)\n",
    "        test_acc, test_f1 = baseline_model.score(testx, testy)\n",
    "        \n",
    "        baseline_target_val_acc_dict[state], baseline_target_test_acc_dict[state] = val_acc, test_acc\n",
    "        baseline_target_val_f1_dict[state], baseline_target_test_f1_dict[state] = val_f1, test_f1\n",
    "\n",
    "print(\"Target State: \")\n",
    "print(f\"average val acc: {np.mean(list(baseline_target_val_acc_dict.values())):.3f}, average val f1: {np.mean(list(baseline_target_val_f1_dict.values())):.3f}\")\n",
    "print(f\"average test acc: {np.mean(list(baseline_target_test_acc_dict.values())):.3f}, average test f1: {np.mean(list(baseline_target_test_f1_dict.values())):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## concat embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# train the model\\nfor state in source_state_list:\\n    root_dir = '/shared/share_mala/llm-dro/income/'\\n    trainx, trainy, valx, valy, testx, testy = load_data('concat', state, root_dir)\\n    # concat all train data into one\\n    if state == source_state_list[0]:\\n        X_train = trainx\\n        y_train = trainy\\n    else:\\n        X_train = np.concatenate((X_train, trainx), axis=0)\\n        y_train = np.concatenate((y_train, trainy), axis=0)\\n\\n## train model\\nmodel = MLPconcatClassifier(input_dim=4096, num_classes = 2, hidden_dim=64, refit_method='pca', initial_embedding_method='wiki')\\nmodel.train_epochs = 100\\nmodel.fit(X_train, y_train)\\n\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# train the model\n",
    "for state in source_state_list:\n",
    "    root_dir = '/shared/share_mala/llm-dro/income/'\n",
    "    trainx, trainy, valx, valy, testx, testy = load_data('concat', state, root_dir)\n",
    "    # concat all train data into one\n",
    "    if state == source_state_list[0]:\n",
    "        X_train = trainx\n",
    "        y_train = trainy\n",
    "    else:\n",
    "        X_train = np.concatenate((X_train, trainx), axis=0)\n",
    "        y_train = np.concatenate((y_train, trainy), axis=0)\n",
    "\n",
    "## train model\n",
    "model = MLPconcatClassifier(input_dim=4096, num_classes = 2, hidden_dim=64, refit_method='pca', initial_embedding_method='wiki')\n",
    "model.train_epochs = 100\n",
    "model.fit(X_train, y_train)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_model = MLPconcatClassifier(input_dim=4096, num_classes = 2, hidden_dim=64, refit_method='pca', initial_embedding_method='wiki')\n",
    "\n",
    "task_name = 'income'\n",
    "source_state_str = '-'.join(source_state_list)\n",
    "embedding_method = 'concat'\n",
    "initial_embedding_method = 'wiki'\n",
    "refit_method = 'pca'\n",
    "save_dir = '/shared/share_mala/llm-dro/'\n",
    "model_dir = f'{save_dir}/save_models/{task_name}/{source_state_str}/{embedding_method}/{initial_embedding_method}/{refit_method}/'    \n",
    "\n",
    "concat_model.load(31, model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source State: \n",
      "average train acc: 0.794, average train f1: 0.782\n",
      "average val acc: 0.808, average val f1: 0.800\n",
      "average test acc: 0.792, average test f1: 0.786\n"
     ]
    }
   ],
   "source": [
    "source_train_acc_dict, source_val_acc_dict, source_test_acc_dict = dict(), dict(), dict()\n",
    "source_train_f1_dict, source_val_f1_dict, source_test_f1_dict = dict(), dict(), dict()\n",
    "\n",
    "## report training, val, testing performance for each state\n",
    "for state in source_state_list:\n",
    "    root_dir = '/shared/share_mala/llm-dro/income/'\n",
    "    trainx, trainy, valx, valy, testx, testy = load_data('concat', state, root_dir)\n",
    "    train_acc, train_f1 = concat_model.score(trainx, trainy)\n",
    "    val_acc, val_f1 = concat_model.score(valx, valy)\n",
    "    test_acc, test_f1 = concat_model.score(testx, testy)\n",
    "    \n",
    "    source_train_acc_dict[state], source_val_acc_dict[state], source_test_acc_dict[state] = train_acc, val_acc, test_acc\n",
    "    source_train_f1_dict[state], source_val_f1_dict[state], source_test_f1_dict[state] = train_f1, val_f1, test_f1\n",
    "\n",
    "print(\"Source State: \")\n",
    "print(f\"average train acc: {np.mean(list(source_train_acc_dict.values())):.3f}, average train f1: {np.mean(list(source_train_f1_dict.values())):.3f}\")\n",
    "print(f\"average val acc: {np.mean(list(source_val_acc_dict.values())):.3f}, average val f1: {np.mean(list(source_val_f1_dict.values())):.3f}\")\n",
    "print(f\"average test acc: {np.mean(list(source_test_acc_dict.values())):.3f}, average test f1: {np.mean(list(source_test_f1_dict.values())):.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target State: \n",
      "average val acc: 0.729, average val f1: 0.692\n",
      "average test acc: 0.714, average test f1: 0.683\n"
     ]
    }
   ],
   "source": [
    "target_train_acc_dict, target_val_acc_dict, target_test_acc_dict = dict(), dict(), dict()\n",
    "target_train_f1_dict, target_val_f1_dict, target_test_f1_dict = dict(), dict(), dict()\n",
    "\n",
    "## report training, val, testing performance for each state\n",
    "for state in ['SD']:\n",
    "    if state not in source_state_list:\n",
    "        root_dir = '/shared/share_mala/llm-dro/income/'\n",
    "        trainx, trainy, valx, valy, testx, testy = load_data('concat', state, root_dir)\n",
    "        #train_acc, train_f1 = baseline_model.score(trainx, trainy)\n",
    "        val_acc, val_f1 = concat_model.score(valx, valy)\n",
    "        test_acc, test_f1 = concat_model.score(testx, testy)\n",
    "        \n",
    "        target_val_acc_dict[state], target_test_acc_dict[state] = val_acc, test_acc\n",
    "        target_val_f1_dict[state], target_test_f1_dict[state] = val_f1, test_f1\n",
    "\n",
    "print(\"target State: \")\n",
    "print(f\"average val acc: {np.mean(list(target_val_acc_dict.values())):.3f}, average val f1: {np.mean(list(target_val_f1_dict.values())):.3f}\")\n",
    "print(f\"average test acc: {np.mean(list(target_test_acc_dict.values())):.3f}, average test f1: {np.mean(list(target_test_f1_dict.values())):.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### target states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_state = 'SD'\n",
    "root_dir = '/shared/share_mala/llm-dro/income/'\n",
    "trainx, trainy, valx, valy, testx, testy = load_data('concat', target_state, root_dir, num_val=100)\n",
    "# concat all train data into one\n",
    "refitX = valx\n",
    "refity = valy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [03:05<00:00,  2.70it/s]\n"
     ]
    }
   ],
   "source": [
    "concat_model.load(31, model_dir)\n",
    "concat_model.model.embedding.coefficients\n",
    "concat_model.refit_epochs = 500\n",
    "concat_model.refit_lr = 0.1\n",
    "concat_model.refit(refitX, refity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "refit target State: \n",
      "average val acc: 0.733, average val f1: 0.693\n",
      "average test acc: 0.718, average test f1: 0.685\n"
     ]
    }
   ],
   "source": [
    "refit_target_val_acc_dict, refit_target_test_acc_dict =  dict(), dict()\n",
    "refit_target_val_f1_dict, refit_target_test_f1_dict =  dict(), dict()\n",
    "\n",
    "# record the performance of the target states\n",
    "for state in ['SD']:\n",
    "    if state not in source_state_list:\n",
    "        root_dir = '/shared/share_mala/llm-dro/income/'\n",
    "        trainx, trainy, valx, valy, testx, testy = load_data('concat', state, root_dir)\n",
    "        \n",
    "        val_acc, val_f1 = concat_model.score(valx, valy)\n",
    "        test_acc, test_f1 = concat_model.score(testx, testy)\n",
    "        refit_target_val_acc_dict[state], refit_target_test_acc_dict[state] =  val_acc, test_acc\n",
    "        refit_target_val_f1_dict[state], refit_target_test_f1_dict[state] = val_f1, test_f1\n",
    "\n",
    "print(\"refit target State: \")\n",
    "print(f\"average val acc: {np.mean(list(refit_target_val_acc_dict.values())):.3f}, average val f1: {np.mean(list(refit_target_val_f1_dict.values())):.3f}\")\n",
    "print(f\"average test acc: {np.mean(list(refit_target_test_acc_dict.values())):.3f}, average test f1: {np.mean(list(refit_target_test_f1_dict.values())):.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test refit func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from refit import * \n",
    "\n",
    "def refit(refitx, refity, test_dict, args):\n",
    "    '''\n",
    "    refit and test models on target states\n",
    "    '''\n",
    "    # load args\n",
    "    task_name, source_state, num_list, year, embedding_method, prompt_method, initial_embedding_method, refit_method, model_name, seed, experiment_id, refit_id, target_state_list, is_regression, gpu_id = args\n",
    "    source_state_str = \"-\".join(source_state)\n",
    "    # set up gpu\n",
    "    if 'mlp' in model_name:\n",
    "        os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(gpu_id)\n",
    "        device = torch.device(f'cuda:{gpu_id}')\n",
    "        torch.cuda.set_device(device)\n",
    "    # set up save dir and path\n",
    "    save_dir = '/shared/share_mala/llm-dro/'\n",
    "    if embedding_method == 'concat':\n",
    "        model_dir = f'{save_dir}/save_models/{task_name}/{source_state_str}/{embedding_method}/{initial_embedding_method}/{refit_method}/'    \n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    if embedding_method == 'concat':\n",
    "        os.makedirs(f'{save_dir}/refit_results/{task_name}/{embedding_method}/{initial_embedding_method}/{refit_method}/{source_state_str}/{model_name}', exist_ok=True)            \n",
    "        path = f'{save_dir}/refit_results/{task_name}/{embedding_method}/{initial_embedding_method}/{refit_method}/{source_state_str}/{model_name}/{experiment_id}_{refit_id}.json'\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "    print(f\"Refit {task_name}-{source_state_str}-{model_name}-ID {experiment_id}-Refit ID {refit_id} begins\")\n",
    "\n",
    "    # check if the experiment has been done\n",
    "    #if os.path.exists(path):\n",
    "    #    return \n",
    "    \n",
    "    # save hyperparamters\n",
    "    result_record = {}    \n",
    "    result_record[\"model\"] = model_name\n",
    "    result_record[\"source_state\"] = source_state_str\n",
    "    result_record[\"year\"] = year\n",
    "    result_record[\"embedding\"] = embedding_method\n",
    "    if embedding_method != 'one_hot':\n",
    "        result_record[\"prompt\"] = prompt_method\n",
    "    \n",
    "    # load trained model and hyperparameters\n",
    "    model = fetch_model('mlp_concat', is_regression, refitx.shape[1]-1, initial_embedding_method=initial_embedding_method, refit_method=refit_method)\n",
    "    config = sample_config(f'mlp_concat_{refit_method}', seed, experiment_id)\n",
    "    if 'mlp' in model_name:\n",
    "        config[\"device\"] = gpu_id\n",
    "    result_record[\"config\"] = config \n",
    "    result_record['initial_embedding_method'] = initial_embedding_method\n",
    "    result_record['refit_method'] = refit_method   \n",
    "    try: \n",
    "        model.load(experiment_id, model_dir)\n",
    "    except:\n",
    "        raise ValueError(f\"Model {model_name}_{experiment_id} not found in {model_dir}\")\n",
    "    # load refit hyperparameters\n",
    "    refit_config = sample_config('refit_mlp_concat', seed, refit_id)\n",
    "    result_record['refit_config'] = refit_config\n",
    "    model.update_refit_config(refit_config)\n",
    "    print(refit_config)\n",
    "\n",
    "    # refit model\n",
    "    model.fit_embeddings(refitx, refity)\n",
    "\n",
    "    # model testing\n",
    "    test_result_acc = {}\n",
    "    test_result_f1 = {}\n",
    "    for target_state in target_state_list:\n",
    "        if target_state in source_state: # do not load if source state\n",
    "            continue\n",
    "        else:\n",
    "            testx, testy = test_dict[target_state]\n",
    "            # save accuracy and f1 score\n",
    "            acc, f1 = model.score(testx, testy)\n",
    "            test_result_acc[target_state] = acc \n",
    "            test_result_f1[target_state] = f1\n",
    "    # save test results\n",
    "    result_record[\"test_result_acc\"] = test_result_acc\n",
    "    result_record[\"test_result_f1\"] = test_result_f1\n",
    "    if 'mlp' in model_name:\n",
    "        result_record[\"config\"][\"device\"] = gpu_id\n",
    "    \n",
    "    # save result\n",
    "    #with open(path, 'w') as f:\n",
    "    #    json.dump(result_record, f)\n",
    "    del model \n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect() \n",
    "    print(f\"Experiment {task_name}-{source_state_str}-{model_name}-ID {experiment_id}-Refit ID {refit_id} finished!!\")\n",
    "    return result_record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup args\n",
    "task = 'income'\n",
    "source = ['CA', 'TX', 'FL', 'NY', 'PA']\n",
    "num = [5000, 5000, 5000, 5000, 5000]\n",
    "year = 2018\n",
    "embedding = 'concat'\n",
    "prompt = None\n",
    "initial_embedding_method = 'wiki'\n",
    "refit_method = 'pca'\n",
    "model = 'mlp'\n",
    "experiment_id = 31\n",
    "refit_id = 14\n",
    "num_gpus = torch.cuda.device_count()\n",
    "\n",
    "arg = task, source, num, 2018, embedding, prompt, initial_embedding_method, refit_method, model, 0, experiment_id, refit_id, ALL_STATES, 0, experiment_id%num_gpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23552, 4097) (23552,)\n"
     ]
    }
   ],
   "source": [
    "# load validation and test data\n",
    "valx, valy, test_dict = load_val_test_data(arg)\n",
    "print(valx.shape, valy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Refit income-CA-TX-FL-NY-PA-mlp-ID 31-Refit ID 14 begins\n",
      "{'refit_lr': 0.001, 'refit_epochs': 200, 'refit_num': 512}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [04:08<00:00,  1.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment income-CA-TX-FL-NY-PA-mlp-ID 31-Refit ID 14 finished!!\n"
     ]
    }
   ],
   "source": [
    "### refit model\n",
    "result_record = refit(valx, valy, test_dict, arg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "refit target State: \n",
      "average test acc: 0.805, average test f1: 0.774\n"
     ]
    }
   ],
   "source": [
    "print(\"refit target State: \")\n",
    "print(f\"average test acc: {np.mean(list(result_record['test_result_acc'].values())):.3f}, average test f1: {np.mean(list(result_record['test_result_f1'].values())):.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train import *\n",
    "from refit import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_method = 'one_hot'\n",
    "prompt_method = None\n",
    "target_state_list = ['WY', 'PR']\n",
    "year = 2018\n",
    "seed = 0\n",
    "\n",
    "source_state_list = ['CA']\n",
    "task_name = 'mobility'\n",
    "save_dir = '/shared/share_mala/llm-dro/'\n",
    "refit_dict = {}   # validation data\n",
    "test_dict = {}\n",
    "refit_num = 1024\n",
    "# load validation and test data\n",
    "for idx, state in enumerate(target_state_list):\n",
    "    if state in source_state_list: # do not load if source state\n",
    "        continue\n",
    "    else: # load validation/test data if target state\n",
    "        X, y = get_raw_data(task_name, embedding_method, prompt_method, \n",
    "                            state, save_dir, year)\n",
    "        # check if refit num is larger than the data size\n",
    "        if refit_num > X.shape[0]:\n",
    "            cur_refit_num = X.shape[0] // 2\n",
    "        else:\n",
    "            cur_refit_num = refit_num\n",
    "        # sample training/validation data\n",
    "        valx, valy, testx, testy = sample_val_test_data(X, y, val_num = cur_refit_num, seed=seed)  \n",
    "        refit_dict[state] = [valx, valy]\n",
    "        test_dict[state] = [testx, testy]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(509, 63)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dict['WY'][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4730"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sftpy310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
